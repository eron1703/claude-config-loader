# Shared Development Tools - dev-01 (65.21.153.235)
# Helsinki, CCX23 16GB
#
# PREPARATION CONFIG ONLY - Not for direct deployment without review.
# This file documents the shared tools stack that runs alongside FlowMaster on dev-01.
#
# Existing services NOT in this compose (managed separately):
#   - FlowMaster K3S cluster (frontend:3000, backend:8000, ArangoDB:8529, etc.)
#   - SDX Platform (backend:8010, frontend:3010, mcp-server:8011)
#   - GitLab Runner (flowmaster-demo-runner)
#
# Port allocation:
#   3000-3010  - FlowMaster/SDX frontends (RESERVED)
#   5432       - FlowMaster PostgreSQL (RESERVED)
#   8000-8011  - FlowMaster/SDX backends (RESERVED)
#   8083       - Plane Web UI
#   8099       - Agent Chat / Telemetry
#   8529       - ArangoDB (RESERVED)
#   3001       - Grafana
#   9090       - Prometheus
#   9100       - Node Exporter

version: "3.8"

networks:
  shared-tools:
    name: shared-tools
    driver: bridge
  plane-net:
    name: plane-net
    driver: bridge

volumes:
  plane-pgdata:
  plane-redisdata:
  plane-minio-data:
  plane-uploads:
  grafana-data:
  prometheus-data:

# =============================================================================
# PLANE - Project Management (Open Source Jira Alternative)
# https://github.com/makeplane/plane
# =============================================================================

x-plane-env: &plane-env
  DATABASE_URL: postgresql://plane:${PLANE_DB_PASSWORD}@plane-db:5432/plane
  REDIS_URL: redis://plane-redis:6379/
  SECRET_KEY: ${PLANE_SECRET_KEY}
  AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
  AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
  AWS_S3_ENDPOINT_URL: http://plane-minio:9000
  AWS_S3_BUCKET_NAME: plane-uploads
  AWS_REGION: ""
  USE_MINIO: "1"
  MINIO_ROOT_USER: ${MINIO_ROOT_USER}
  MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
  WEB_URL: http://${SERVER_IP}:8083
  CORS_ALLOWED_ORIGINS: http://${SERVER_IP}:8083
  GUNICORN_WORKERS: 2
  ENABLE_SIGNUP: "0"
  ENABLE_MAGIC_LINK_LOGIN: "0"
  API_BASE_URL: http://plane-api:8000

services:

  # ---------------------------------------------------------------------------
  # Plane PostgreSQL (port 5433 to avoid conflict with FlowMaster's 5432)
  # ---------------------------------------------------------------------------
  plane-db:
    image: postgres:15-alpine
    container_name: plane-db
    restart: unless-stopped
    networks:
      - plane-net
    volumes:
      - plane-pgdata:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: plane
      POSTGRES_USER: plane
      POSTGRES_PASSWORD: ${PLANE_DB_PASSWORD}
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U plane -d plane"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M

  # ---------------------------------------------------------------------------
  # Plane Redis
  # ---------------------------------------------------------------------------
  plane-redis:
    image: redis:7-alpine
    container_name: plane-redis
    restart: unless-stopped
    networks:
      - plane-net
    volumes:
      - plane-redisdata:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 256M

  # ---------------------------------------------------------------------------
  # Plane MinIO (S3-compatible object storage)
  # ---------------------------------------------------------------------------
  plane-minio:
    image: minio/minio:latest
    container_name: plane-minio
    restart: unless-stopped
    networks:
      - plane-net
    volumes:
      - plane-minio-data:/data
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M

  # ---------------------------------------------------------------------------
  # Plane API Server
  # ---------------------------------------------------------------------------
  plane-api:
    image: makeplane/plane-backend:stable
    container_name: plane-api
    restart: unless-stopped
    networks:
      - plane-net
    environment:
      <<: *plane-env
    command: >
      bash -c "python manage.py migrate &&
               python manage.py createbuckets &&
               gunicorn plane.asgi:application
               --bind 0.0.0.0:8000
               --workers $${GUNICORN_WORKERS:-2}
               -k uvicorn.workers.UvicornWorker
               --timeout 120"
    depends_on:
      plane-db:
        condition: service_healthy
      plane-redis:
        condition: service_healthy
      plane-minio:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 1G

  # ---------------------------------------------------------------------------
  # Plane Worker (background jobs)
  # ---------------------------------------------------------------------------
  plane-worker:
    image: makeplane/plane-backend:stable
    container_name: plane-worker
    restart: unless-stopped
    networks:
      - plane-net
    environment:
      <<: *plane-env
    command: python manage.py celery
    depends_on:
      plane-db:
        condition: service_healthy
      plane-redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 512M

  # ---------------------------------------------------------------------------
  # Plane Beat Worker (scheduled tasks)
  # ---------------------------------------------------------------------------
  plane-beat-worker:
    image: makeplane/plane-backend:stable
    container_name: plane-beat-worker
    restart: unless-stopped
    networks:
      - plane-net
    environment:
      <<: *plane-env
    command: python manage.py celery_beat
    depends_on:
      plane-db:
        condition: service_healthy
      plane-redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 256M

  # ---------------------------------------------------------------------------
  # Plane Web Frontend
  # ---------------------------------------------------------------------------
  plane-web:
    image: makeplane/plane-frontend:stable
    container_name: plane-web
    restart: unless-stopped
    networks:
      - plane-net
    environment:
      NEXT_PUBLIC_API_BASE_URL: ""
    depends_on:
      - plane-api
    deploy:
      resources:
        limits:
          memory: 512M

  # ---------------------------------------------------------------------------
  # Plane Space (public sharing)
  # ---------------------------------------------------------------------------
  plane-space:
    image: makeplane/plane-space:stable
    container_name: plane-space
    restart: unless-stopped
    networks:
      - plane-net
    environment:
      NEXT_PUBLIC_API_BASE_URL: ""
    depends_on:
      - plane-api
    deploy:
      resources:
        limits:
          memory: 256M

  # ---------------------------------------------------------------------------
  # Plane Admin
  # ---------------------------------------------------------------------------
  plane-admin:
    image: makeplane/plane-admin:stable
    container_name: plane-admin
    restart: unless-stopped
    networks:
      - plane-net
    environment:
      NEXT_PUBLIC_API_BASE_URL: ""
    depends_on:
      - plane-api
    deploy:
      resources:
        limits:
          memory: 256M

  # ---------------------------------------------------------------------------
  # Plane Live (real-time collaboration)
  # ---------------------------------------------------------------------------
  plane-live:
    image: makeplane/plane-live:stable
    container_name: plane-live
    restart: unless-stopped
    networks:
      - plane-net
    environment:
      API_BASE_URL: http://plane-api:8000
      REDIS_URL: redis://plane-redis:6379/
      SECRET_KEY: ${PLANE_SECRET_KEY}
    depends_on:
      - plane-api
      - plane-redis
    deploy:
      resources:
        limits:
          memory: 256M

  # ---------------------------------------------------------------------------
  # Plane Proxy (Nginx - routes to web, space, admin, api, live)
  # ---------------------------------------------------------------------------
  plane-proxy:
    image: makeplane/plane-proxy:stable
    container_name: plane-proxy
    restart: unless-stopped
    networks:
      - plane-net
    ports:
      - "8083:80"
    environment:
      FILE_SIZE_LIMIT: 5242880
      BUCKET_NAME: plane-uploads
    depends_on:
      - plane-web
      - plane-api
      - plane-space
      - plane-live
    deploy:
      resources:
        limits:
          memory: 128M

  # =============================================================================
  # MONITORING STACK - Grafana + Prometheus + Node Exporter
  # =============================================================================

  # ---------------------------------------------------------------------------
  # Prometheus (metrics collection)
  # ---------------------------------------------------------------------------
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    networks:
      - shared-tools
    volumes:
      - prometheus-data:/prometheus
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M

  # ---------------------------------------------------------------------------
  # Node Exporter (host metrics)
  # ---------------------------------------------------------------------------
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    networks:
      - shared-tools
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    deploy:
      resources:
        limits:
          memory: 128M

  # ---------------------------------------------------------------------------
  # Grafana (dashboards & visualization)
  # Already running on port 3001
  # ---------------------------------------------------------------------------
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    networks:
      - shared-tools
    volumes:
      - grafana-data:/var/lib/grafana
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_SERVER_ROOT_URL: http://${SERVER_IP}:3001
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_AUTH_ANONYMOUS_ENABLED: "false"
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M

  # =============================================================================
  # AGENT CHAT / TELEMETRY
  # =============================================================================

  # ---------------------------------------------------------------------------
  # Agent Chat / Telemetry Service
  # Already running on port 8099
  # Lightweight service for agent-to-agent and agent-to-human communication
  # ---------------------------------------------------------------------------
  agent-chat:
    image: node:20-alpine
    container_name: agent-chat
    restart: unless-stopped
    networks:
      - shared-tools
    ports:
      - "8099:8099"
    working_dir: /app
    volumes:
      - ./agent-chat:/app
    environment:
      PORT: "8099"
      NODE_ENV: production
      LOG_LEVEL: ${AGENT_CHAT_LOG_LEVEL:-info}
      TELEMETRY_ENABLED: ${AGENT_CHAT_TELEMETRY_ENABLED:-true}
    command: ["node", "server.js"]
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8099/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
